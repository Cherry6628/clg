{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "562e919a-ac43-4f03-b9be-37da104361af",
   "metadata": {},
   "source": [
    "Ex.No: 3 Implement a perceptron in TensorFlow/Keras Environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027970e0-cf35-4f21-971f-72722337d7a8",
   "metadata": {},
   "source": [
    "Aim: To write a python coding to implement perceptron in TensorFlow/keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d55cf1b9-30a9-4fb3-ac65-1ff95000713e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00237792 0.95932017 0.00646385 0.00237792 0.00237792 0.00237792\n",
      " 0.00237792 0.01757056 0.00237792 0.00237792]\n",
      "Epoch 1/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.2671 - loss: 2.2163 - val_accuracy: 0.7189 - val_loss: 1.6527\n",
      "Epoch 2/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7155 - loss: 1.4747 - val_accuracy: 0.7983 - val_loss: 0.9802\n",
      "Epoch 3/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7955 - loss: 0.9099 - val_accuracy: 0.8559 - val_loss: 0.6521\n",
      "Epoch 4/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8531 - loss: 0.6328 - val_accuracy: 0.8870 - val_loss: 0.4853\n",
      "Epoch 5/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8823 - loss: 0.4858 - val_accuracy: 0.9003 - val_loss: 0.3973\n",
      "Epoch 6/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8972 - loss: 0.4043 - val_accuracy: 0.9090 - val_loss: 0.3464\n",
      "Epoch 7/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9055 - loss: 0.3550 - val_accuracy: 0.9149 - val_loss: 0.3134\n",
      "Epoch 8/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9130 - loss: 0.3217 - val_accuracy: 0.9188 - val_loss: 0.2899\n",
      "Epoch 9/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9181 - loss: 0.2973 - val_accuracy: 0.9234 - val_loss: 0.2720\n",
      "Epoch 10/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9227 - loss: 0.2782 - val_accuracy: 0.9272 - val_loss: 0.2575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1cb0f7510d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Activation\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# softmax practice\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "scores = [1, 7, 2, 1, 1, 1, 1, 3, 1, 1]\n",
    "print(softmax(scores))\n",
    "\n",
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "except Exception: \n",
    "    pass\n",
    "\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "gray_scale = 255\n",
    "x_train /= gray_scale\n",
    "x_test /= gray_scale\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)), # reshape 28 row * 28 column data to 28*28 rows\n",
    "    Dense(256, activation='sigmoid'), # dense layer 1\n",
    "    Dense(128, activation='sigmoid'), # dense layer 2\n",
    "    Dense(10, activation='softmax') # dense layer 3\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) \n",
    "model.fit(x_train, y_train, epochs=10, batch_size=2000, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66f6352-6953-4617-8143-7f2fe7a2c671",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
