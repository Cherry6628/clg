{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37b50204-f604-456d-9d3e-d218da252ebd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\_z_\\anaconda_projects\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: numpy in d:\\_z_\\anaconda_projects\\lib\\site-packages (1.24.3)\n",
      "Requirement already satisfied: requests in d:\\_z_\\anaconda_projects\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: opencv-python in d:\\_z_\\anaconda_projects\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: imutils in d:\\_z_\\anaconda_projects\\lib\\site-packages (0.5.4)\n",
      "Requirement already satisfied: scikit-learn in d:\\_z_\\anaconda_projects\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: scipy in d:\\_z_\\anaconda_projects\\lib\\site-packages (1.10.0)\n",
      "Requirement already satisfied: Pillow in d:\\_z_\\anaconda_projects\\lib\\site-packages (10.2.0)\n",
      "Requirement already satisfied: keras in d:\\_z_\\anaconda_projects\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: tensorflow in d:\\_z_\\anaconda_projects\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: scikit-image in d:\\_z_\\anaconda_projects\\lib\\site-packages (0.23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\harisanju\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from requests) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: absl-py in d:\\_z_\\anaconda_projects\\lib\\site-packages (from keras) (1.4.0)\n",
      "Requirement already satisfied: rich in d:\\_z_\\anaconda_projects\\lib\\site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in d:\\_z_\\anaconda_projects\\lib\\site-packages (from keras) (0.0.7)\n",
      "Requirement already satisfied: h5py in d:\\_z_\\anaconda_projects\\lib\\site-packages (from keras) (3.10.0)\n",
      "Requirement already satisfied: optree in d:\\_z_\\anaconda_projects\\lib\\site-packages (from keras) (0.10.0)\n",
      "Requirement already satisfied: ml-dtypes in d:\\_z_\\anaconda_projects\\lib\\site-packages (from keras) (0.3.2)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.7)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in d:\\_z_\\anaconda_projects\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in d:\\_z_\\anaconda_projects\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\harisanju\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: networkx>=2.8 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from scikit-image) (3.3)\n",
      "Requirement already satisfied: imageio>=2.33 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from scikit-image) (2.34.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from scikit-image) (2024.4.24)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from scikit-image) (0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\harisanju\\appdata\\roaming\\python\\python311\\site-packages (from rich->keras) (2.16.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\_z_\\anaconda_projects\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy requests opencv-python imutils scikit-learn scipy Pillow keras tensorflow scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f61ca74-cabf-42fc-ac2c-dc0b2f2e6766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import random\n",
    "import cv2\n",
    "import imutils\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import scipy.spatial.distance\n",
    "\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications import vgg16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, InputLayer\n",
    "from keras import optimizers, regularizers\n",
    "from skimage import transform\n",
    "from skimage.util import random_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58746473-b546-4a2c-9fd2-dfb95358b4bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m             df\u001b[38;5;241m.\u001b[39mdrop(index, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X, df\n\u001b[1;32m---> 19\u001b[0m X_list, df \u001b[38;5;241m=\u001b[39m get_img_arrays(\u001b[43mdf\u001b[49m)\n\u001b[0;32m     20\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X_list)\n\u001b[0;32m     22\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msports\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentertainment\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "def get_img_arrays(df_l):\n",
    "    X = []\n",
    "    df = df_l.copy()\n",
    "    for index,row in df_l.iterrows():\n",
    "        try:\n",
    "            response = requests.get(row['url'], headers = headers)\n",
    "            image_io = BytesIO(response.content)\n",
    "            img = Image.open(image_io)\n",
    "            img = img.resize((150, 150)) # resize to 150x150x3\n",
    "            img = np.array(img)\n",
    "            if img.shape!=(150,150,3):\n",
    "                df.drop(index, inplace=True)\n",
    "            else:\n",
    "                X.append(img)\n",
    "        except:\n",
    "            df.drop(index, inplace=True)\n",
    "    return X, df\n",
    "\n",
    "X_list, df = get_img_arrays(df)\n",
    "X = np.array(X_list)\n",
    "\n",
    "df['category'] = df['category'].str.replace('sports','entertainment')\n",
    "df['category'] = df['category'].str.replace('art','museums')\n",
    "\n",
    "df_under = df.copy()\n",
    "grouped = df_under.groupby('category')\n",
    "museum_len = len(grouped.get_group('museums'))\n",
    "parks_len = len(grouped.get_group('parks'))\n",
    "num_to_remove = parks_len - museum_len\n",
    "\n",
    "parks_indexes = grouped.get_group('parks').index.tolist()\n",
    "indexes_to_remove = random.sample(parks_indexes, num_to_remove)\n",
    "\n",
    "df_under.drop(df_under.index[indexes_to_remove], inplace = True)\n",
    "X_under = np.delete(X, indexes_to_remove, 0)\n",
    "y = df_under['category']\n",
    "\n",
    "X_std = X_under / 255\n",
    "\n",
    "y_ohe = pd.get_dummies(y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_std, y_ohe, test_size=0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25)\n",
    "\n",
    "\n",
    "def get_img_flip(img):\n",
    "    return np.fliplr(img)\n",
    "\n",
    "def get_img_transform(img):\n",
    "    return transform.rotate(img, random.uniform(-30,30))\n",
    "\n",
    "def get_img_noise(img):\n",
    "    return random_noise(img, mode='s&p', clip=True)\n",
    "\n",
    "X_train_aug = []\n",
    "y_train_aug = []\n",
    "\n",
    "for idx in range(0,len(X_train)):\n",
    "    X_train_aug.append(X_train[idx])\n",
    "    X_train_aug.append(get_img_flip(X_train[idx]))\n",
    "    X_train_aug.append(get_img_transform(X_train[idx]))\n",
    "    X_train_aug.append(get_img_noise(X_train[idx]))\n",
    "    y_train_aug.append(y_train.iloc[idx,0])\n",
    "    y_train_aug.append(y_train.iloc[idx,0])\n",
    "    y_train_aug.append(y_train.iloc[idx,0])\n",
    "    y_train_aug.append(y_train.iloc[idx,0])\n",
    "\n",
    "\n",
    "def get_bottleneck_features(model, input_imgs):\n",
    "    features = model.predict(input_imgs, verbose=0)\n",
    "    return features\n",
    "\n",
    "inputs = (150, 150, 3)\n",
    "vgg = vgg16.VGG16(include_top=False, weights='imagenet', input_shape=inputs)\n",
    "\n",
    "output = vgg.layers[-1].output\n",
    "output = keras.layers.Flatten()(output)\n",
    "vgg_model = Model(vgg.input, output)\n",
    "\n",
    "vgg_model.trainable = False\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "X_train_aug_vgg = get_bottleneck_features(vgg_model, X_train_aug)\n",
    "X_val_vgg = get_bottleneck_features(vgg_model, X_val)\n",
    "X_test_vgg = get_bottleneck_features(vgg_model, X_test)\n",
    "\n",
    "batch_s = 400\n",
    "learning_rate = 0.00005\n",
    "dropout = 0.55\n",
    "epochs_num = 10\n",
    "l2_loss_lambda = 0.00000001\n",
    "n_classes = len(y_train_aug.columns)\n",
    "l2 = regularizers.l2(l2_loss_lambda)\n",
    "input_shape = vgg_model.output_shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(input_shape,)))\n",
    "model.add(Dense(1000, activation='relu', kernel_regularizer=l2, input_dim=input_shape))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(1000, activation='relu', kernel_regularizer=l2))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(1000, activation='relu', kernel_regularizer=l2))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(1000, activation='relu', kernel_regularizer=l2))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(n_classes, activation='sigmoid', kernel_regularizer=l2))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_vgg = model.fit(X_train_aug_vgg, y_train_aug, batch_size=batch_s,\n",
    "                        epochs=epochs_num,\n",
    "                        validation_data=(X_val_vgg, y_val), verbose=1)\n",
    "\n",
    "\n",
    "def histogram(image, mask, bins):\n",
    "    ''' get histogram of reg, green, and blue color distribution feature vectors for a\n",
    "    section of an image (represented by a mask)\n",
    "    return 3 histograms as a single color feature vecotr\n",
    "    '''\n",
    "    hist = cv2.calcHist([image], [0,1,2], mask, [bins[0],bins[1],bins[2]],[0, 180, 0, 256, 0, 256])\n",
    "    if imutils.is_cv2():\n",
    "        hist = cv2.normalize(hist).flatten()\n",
    "    else:\n",
    "        hist = cv2.normalize(hist, hist).flatten()\n",
    "    return hist\n",
    "\n",
    "def get_color_description(img_array, bins):\n",
    "    '''\n",
    "    get color distribution feature vector for an image with specified number of bins\n",
    "    split image up into 5 sections, 4 corners and a center ellipse, getting r,g, and b\n",
    "    distribution vectors\n",
    "    '''\n",
    "    color = cv2.COLOR_BGR2HSV\n",
    "    img = img_array * 255\n",
    "    image = cv2.cvtColor(img, color)\n",
    "    features = []\n",
    "    (h, w) = image.shape[:2]\n",
    "    (cX, cY) = (int(w * 0.5), int(h * 0.5))\n",
    "    segments = [(0, cX, 0, cY), (cX, w, 0, cY), (cX, w, cY, h), (0, cX, cY, h)]\n",
    "    (axesX, axesY) = (int(w * 0.75) // 2, int(h * 0.75) // 2)\n",
    "    ellipMask = np.zeros(image.shape[:2], dtype=\"uint8\")\n",
    "    cv2.ellipse(ellipMask, (cX, cY), (axesX, axesY), 0, 0, 360, 255, -1)\n",
    "    for (startX, endX, startY, endY) in segments:\n",
    "        cornerMask = np.zeros(image.shape[:2], dtype=\"uint8\")\n",
    "        cv2.rectangle(cornerMask, (startX, startY), (endX, endY), 255, -1)\n",
    "        cornerMask = cv2.subtract(cornerMask, ellipMask)\n",
    "        hist = histogram(image, cornerMask, bins)\n",
    "        features.extend(hist)\n",
    "    hist = histogram(image, ellipMask, bins)\n",
    "    features.extend(hist)\n",
    "    return features\n",
    "\n",
    "bins = [8, 8, 8]\n",
    "color_feats = []\n",
    "for x in X:\n",
    "    color_feats.append(get_color_description(x, bins))\n",
    "\n",
    "feats_arr = get_bottleneck_features(vgg_model, X)\n",
    "\n",
    "df['color_feats'] = color_feats\n",
    "df['vgg_feats'] = feats_arr\n",
    "\n",
    "grouped = df.groupby('category')\n",
    "\n",
    "\n",
    "def classify(img_vgg, model):\n",
    "    '''\n",
    "    find class using cnn model, using imgvgg vector and return prediction\n",
    "    '''\n",
    "    cats = ['beaches/ocean', 'entertainment', 'gardens/zoo', 'landmarks', 'museums', 'parks']\n",
    "    predictions = np.array(model.predict(img_vgg))\n",
    "    pred = np.argmax(predictions)\n",
    "    return cats[pred]\n",
    "\n",
    "def get_distance(img_feats, feats):\n",
    "    '''\n",
    "    get distance between vectors\n",
    "    '''\n",
    "    return returnscipy.spatial.distance.cosine(img_feats, feats)\n",
    "\n",
    "def get_recommendations(img_class, img_array, img_vgg, df):\n",
    "    '''\n",
    "    get df of top attractions and display 3 images from top attractions\n",
    "    '''\n",
    "    bins = [8, 8, 8]\n",
    "    img_color_des = get_color_description(img_array, bins)\n",
    "    df['color_feats'] = df.apply(lambda row: get_distance(img_color_des, row['color_feats']), axis=1)\n",
    "    df['vgg_feats'] = df.apply(lambda row: get_distance(img_vgg, row['vgg_feats']), axis=1)\n",
    "    \n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    color_array = df['color_feats'].values.astype(float).reshape(-1, 1)\n",
    "    scaled_color_array = min_max_scaler.fit_transform(color_array)\n",
    "    vgg_array = df['vgg_feats'].values.astype(float).reshape(-1, 1)\n",
    "    scaled_vgg_array = min_max_scaler.fit_transform(vgg_array)\n",
    "    \n",
    "    df.drop(['color_feats', 'vgg_feats'], axis=1, inplace=True)\n",
    "    \n",
    "    if img_class in ['beaches/oceans']:\n",
    "        total_distance = 0.5 * scaled_vgg_array + scaled_color_array\n",
    "    elif img_class in ['gardens/zoo']:\n",
    "        total_distance = 10 * scaled_vgg_array + scaled_color_array\n",
    "    elif img_class in ['entertainment', 'landmarks', 'museums']:\n",
    "        total_distance = 20 * scaled_vgg_array + scaled_color_array\n",
    "    else:\n",
    "        total_distance = 1 * scaled_vgg_array + scaled_color_array\n",
    "    \n",
    "    df['distance'] = total_distance\n",
    "    \n",
    "    grouped_df = df.groupby(['name', 'location'])['distance'].mean()\n",
    "    grouped_df = pd.DataFrame(grouped_df).reset_index()\n",
    "    \n",
    "    grouped_df['length'] = grouped_df.location.str.len()\n",
    "    grouped_df = grouped_df[grouped_df.length > 3]\n",
    "    \n",
    "    grouped_df.sort_values(by=['distance'], ascending=True, inplace=True)\n",
    "    \n",
    "    top_df = grouped_df[:3].reset_index()\n",
    "    atts = [top_df.loc[0, 'name'], top_df.loc[1, 'name'], top_df.loc[2, 'name']]\n",
    "    \n",
    "    grouped = df.groupby('name')\n",
    "    groups = []\n",
    "    for attraction in atts:\n",
    "        groups.append(grouped.get_group(attraction))\n",
    "    \n",
    "    show_recommendations(groups, atts)\n",
    "    return top_df\n",
    "\n",
    "def show_recommendations(groups, atts):\n",
    "    '''\n",
    "    show 3 images for each recommended attraction\n",
    "    '''\n",
    "    for idx, group in enumerate(groups):\n",
    "        df = pd.DataFrame(group).reset_index()\n",
    "        imgs = [df.loc[0, 'url'], df.loc[2, 'url'], df.loc[5, 'url']]\n",
    "        fig = plt.figure()\n",
    "        fig.suptitle(atts[idx], fontsize=\"x-large\")\n",
    "        for i in range(3):\n",
    "            a = fig.add_subplot(1, 3, i+1)\n",
    "            image = load_image(imgs[i])\n",
    "            plt.imshow(image, cmap='Greys_r')\n",
    "            plt.axis('off')\n",
    "\n",
    "def input_img_load_to_array(path):\n",
    "    image = Image.open(path)\n",
    "    img = image.resize((150, 150))\n",
    "    return ((np.array(img))/255)\n",
    "\n",
    "path = 'path to test img'\n",
    "input_img = input_img_load_to_array(path)\n",
    "img_vgg = get_bottleneck_features(vgg_model, np.array([input_img]))\n",
    "\n",
    "label = classify(img_vgg, model)\n",
    "group = grouped.get_group(label)\n",
    "top_3 = get_recommendations(label, image_array, img_vgg, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e267a170-7605-45d2-9105-fe3ce6dcab70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
